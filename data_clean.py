# === 1. æ¸…æ´—ç­–ç•¥æ–‡ä»¶ ===
import os, torch
import json,chromadb
import re
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline
from transformers import PegasusTokenizer, PegasusForConditionalGeneration, pipeline
from tqdm import tqdm
from transformers import PegasusForConditionalGeneration
from chromadb.config import Settings

# === æ–‡ä»¶å¤¹è·¯å¾„é…ç½® ===
STRATEGY_FOLDER = "Strategy"
RECORD_FOLDER = os.path.join(STRATEGY_FOLDER, "Records")
OUTPUT_FOLDER = "cleaned_output"
os.makedirs(OUTPUT_FOLDER, exist_ok=True)

# === å·¥å…·å‡½æ•°ï¼šæ¸…æ´—æ®µè½å¹¶æŒ‰éœ€åˆ‡å‰² ===
def clean_and_split_text(text, max_length=300):
    paragraphs = re.split(r'\n\s*\n', text)
    chunks = []

    for para in paragraphs:
        para = para.strip()
        if not para:
            continue

        if len(para) <= max_length:
            chunks.append(para)
        else:
            # æ®µè½è¿‡é•¿ï¼ŒæŒ‰ä¸­æ–‡å¥å­æ–­å¥
            sentences = re.split(r'(?<=[ã€‚ï¼ï¼Ÿ])', para)
            buffer = ""
            for sentence in sentences:
                if len(buffer) + len(sentence) <= max_length:
                    buffer += sentence
                else:
                    if buffer:
                        chunks.append(buffer.strip())
                    buffer = sentence
            if buffer:
                chunks.append(buffer.strip())

    return chunks
# === 1. æ¸…æ´—ç­–ç•¥æ–‡ä»¶ ===
def clean_strategies():
    strategy_chunks = []
    for file in os.listdir(STRATEGY_FOLDER):
        path = os.path.join(STRATEGY_FOLDER, file)
        if file.endswith(".txt") and os.path.isfile(path):
            with open(path, "r", encoding="utf-8") as f:
                content = f.read()
                chunks = clean_and_split_text(content)
                for chunk in chunks:
                    strategy_chunks.append({"type": "tip", "text": chunk})
    with open(os.path.join(OUTPUT_FOLDER, "cleaned_tips.jsonl"), "w", encoding="utf-8") as f:
        for item in strategy_chunks:
            f.write(json.dumps(item, ensure_ascii=False) + "\n")
    print(f"âœ… ç­–ç•¥æ–‡ä»¶å·²æ¸…æ´—å¹¶ä¿å­˜ï¼Œå…± {len(strategy_chunks)} æ¡")
# === è§£æä¸€å±€å®Œæ•´æ¸¸æˆè®°å½•ä¸ºç»“æ„åŒ–æ¡ç›® ===
def parse_detailed_match_record(content, game_id):
    rounds = re.split(r"â”€+\nç¬¬\s*(\d+)\s*è½®\nâ”€+", content)
    parsed = []

    for i in range(1, len(rounds), 2):
        try:
            round_num = int(rounds[i])
            round_text = rounds[i + 1]

            # ä¸´æ—¶å­˜å‚¨æ¯ä½ç©å®¶çš„è¡Œä¸º
            player_actions = {}

            # è§£æå‡ºç‰Œè®°å½•
            plays = re.findall(
                r"è½®åˆ°\s*(\w+)\s*å‡ºç‰Œ.*?å‡ºç‰Œï¼š([^\n]+).*?å‡ºç‰Œç†ç”±ï¼š(.+?)(?=(?:è½®åˆ°|\Z))",
                round_text,
                re.DOTALL
            )

            for player, cards_text, reason in plays:
                player = player.strip()
                played_cards = []
                hand_cards = []
                target_cards = []

                parts = re.split(r"[ã€,ï¼Œ\s]+", cards_text.strip())
                for part in parts:
                    if not part.strip():
                        continue
                    if "å‰©ä½™æ‰‹ç‰Œ" in part:
                        match = re.search(r"å‰©ä½™æ‰‹ç‰Œ[:ï¼š]?(.*)", part)
                        if match:
                            hand_cards += [x.strip() for x in re.split(r"[ã€,ï¼Œ\s]+", match.group(1)) if x.strip()]
                    elif "ç›®æ ‡ç‰Œ" in part:
                        match = re.search(r"ç›®æ ‡ç‰Œ[:ï¼š]?(.*)", part)
                        if match:
                            target_cards += [x.strip("()") for x in re.split(r"[ã€,ï¼Œ\s]+", match.group(1)) if x.strip()]
                    else:
                        played_cards.append(part.strip())

                if player not in player_actions:
                    player_actions[player] = {
                        "type": "action",
                        "game_id": game_id,
                        "round": round_num,
                        "player": player,
                        "played_cards": [],
                        "hand_cards": [],
                        "target_cards": [],
                        "play_reason": "",
                        "challenge": None,
                        "challenge_reason": ""
                    }

                player_actions[player]["played_cards"] = played_cards
                player_actions[player]["hand_cards"] = hand_cards
                player_actions[player]["target_cards"] = target_cards
                player_actions[player]["play_reason"] = reason.strip()

            # è§£æè´¨ç–‘è®°å½•
            challenges = re.findall(
                r"(\w+)\s+é€‰æ‹©(ä¸)?è´¨ç–‘.*?ç†ç”±ï¼š(.+?)(?=(?:è½®åˆ°|\Z))",
                round_text,
                re.DOTALL
            )

            for challenger, no_flag, reason in challenges:
                challenger = challenger.strip()
                if challenger not in player_actions:
                    player_actions[challenger] = {
                        "type": "action",
                        "game_id": game_id,
                        "round": round_num,
                        "player": challenger,
                        "played_cards": [],
                        "hand_cards": [],
                        "target_cards": [],
                        "play_reason": "",
                        "challenge": None,
                        "challenge_reason": ""
                    }

                player_actions[challenger]["challenge"] = not bool(no_flag)
                player_actions[challenger]["challenge_reason"] = reason.strip()

            # åˆå¹¶ç»“æœ
            parsed.extend(player_actions.values())

        except Exception as e:
            print(f"âš ï¸ è·³è¿‡ Round {rounds[i]}ï¼Œé”™è¯¯: {e}")

    return parsed



# === å¤„ç†æ‰€æœ‰å¯¹å±€è®°å½•æ–‡ä»¶ ===
def clean_records():
    cases = []
    if not os.path.exists(RECORD_FOLDER):
        print("âš ï¸ Records æ–‡ä»¶å¤¹ä¸å­˜åœ¨ï¼Œè·³è¿‡å¯¹å±€è®°å½•æ¸…æ´—")
        return

    for file in os.listdir(RECORD_FOLDER):
        path = os.path.join(RECORD_FOLDER, file)
        if file.endswith(".txt") and os.path.isfile(path):
            with open(path, "r", encoding="utf-8") as f:
                content = f.read()
                # å°è¯•æå–æ¸¸æˆç¼–å·
                game_id_match = re.search(r"æ¸¸æˆç¼–å·[:ï¼š]\s*([\w\d_]+)", content)
                game_id = game_id_match.group(1) if game_id_match else file
                parsed_rounds = parse_detailed_match_record(content, game_id)
                cases.extend(parsed_rounds)

    output_path = os.path.join(OUTPUT_FOLDER, "cleaned_cases.jsonl")
    with open(output_path, "w", encoding="utf-8") as f:
        for item in cases:
            f.write(json.dumps(item, ensure_ascii=False) + "\n")

    print(f"âœ… å¯¹å±€è®°å½•å·²æ¸…æ´—å¹¶ä¿å­˜ï¼Œå…± {len(cases)} æ¡")

def preprocess_text(text: str) -> str:
    # åˆ é™¤ç‰¹æ®Šæ§åˆ¶ç¬¦å’Œå¼‚å¸¸å­—ç¬¦
    text = text.replace("\n", " ").replace("\r", " ")
    text = re.sub(r"[^\x20-\x7E\u4e00-\u9fa5ã€‚ï¼Œï¼Ÿï¼ã€ã€‘ï¼ˆï¼‰â€œâ€â€˜â€™]", "", text)
    return text.strip()

def compress_play_reasons(
    input_path: str,
    output_path: str,
    model_name: str = "fnlp/bart-base-chinese",
    device: int = 0,
    max_len: int = 60,
    min_len: int = 30
):

    if not os.path.exists(input_path):
        raise FileNotFoundError(f"âŒ æ‰¾ä¸åˆ°è¾“å…¥æ–‡ä»¶ï¼š{input_path}")

    print(f"ğŸ“¦ æ­£åœ¨åŠ è½½æ¨¡å‹ {model_name}...")
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False)
    model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(f"cuda:{device}" if torch.cuda.is_available() else "cpu")

    summarizer = pipeline(
        "summarization",
        model=model,
        tokenizer=tokenizer,
        device=device,
        max_length=None
    )

    with open(input_path, "r", encoding="utf-8") as f_in, \
         open(output_path, "w", encoding="utf-8") as f_out:

        for line in tqdm(f_in, desc="ğŸ”„ æ­£åœ¨å‹ç¼©æ¯ä¸ª reason"):
            try:
                data = json.loads(line)
                if "play_reason" in data and isinstance(data["play_reason"], str) and len(data["play_reason"]) > 0:
                    original = preprocess_text(data["play_reason"])
                    try:
                        summary = summarizer(original, max_new_tokens=max_len, min_length=min_len, do_sample=False)
                        reason = summary[0]["summary_text"].strip()
                        data["play_reason"] = reason.replace(" ", "")

                    except Exception as e:
                        print(f"âš ï¸ å‹ç¼©å¤±è´¥ï¼Œä¿ç•™åŸå§‹æ–‡æœ¬: {e}")
                        data["play_reason"] = original
                if data['challenge'] is not None and "challenge_reason" in data and isinstance(data["challenge_reason"], str):
                    original = preprocess_text(data["challenge_reason"])
                    try:
                        summary = summarizer(original, max_new_tokens=max_len, min_length=min_len, do_sample=False)
                        reason = summary[0]["summary_text"].strip()
                        data["challenge_reason"] = reason.replace(" ", "")

                    except Exception as e:
                        print(f"âš ï¸ å‹ç¼©å¤±è´¥ï¼Œä¿ç•™åŸå§‹æ–‡æœ¬: {e}")
                        data["challenge_reason"] = original
                torch.cuda.empty_cache()


                f_out.write(json.dumps(data, ensure_ascii=False) + "\n")

            except json.JSONDecodeError:
                print("âŒ JSON è§£ç å¤±è´¥ï¼Œè·³è¿‡æ­¤è¡Œ")
                continue

    print(f"\nâœ… play_reason å‹ç¼©å®Œæˆï¼è¾“å‡ºæ–‡ä»¶ä½äºï¼š{output_path}")

# === ä¸»ç¨‹åºå…¥å£ ===
# if __name__ == "__main__":
#     clean_records()
compress_play_reasons(
    input_path="cleaned_output/cleaned_cases.jsonl",
    output_path="cleaned_output/compressed_cases.jsonl",
    device=0  # ä½¿ç”¨ç¬¬ä¸€å¼  GPUï¼›å¦‚æƒ³ç”¨ CPU è®¾ç½®ä¸º -1
)
# if __name__ == "__main__":
#     clean_strategies()
#     clean_records()
